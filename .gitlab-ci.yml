stages:
  - Migrate to Client's GitHub
  - Merge Request Check

workflow:
  rules:
    - if: $CLIENT_NAME && $CI_COMMIT_REF_NAME == 'develop'
    - if: $CLIENT_NAME && $CI_COMMIT_REF_NAME == 'amith/dbt-pipeline'
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    # - if: $CI_PIPELINE_SOURCE == 'push'

# Code Migration to Client
copy_config_files:
  rules:
    - if: $CLIENT_NAME
  stage: Migrate to Client's GitHub
  image: gcr.io/google.com/cloudsdktool/google-cloud-cli:latest
  before_script:
    - gcloud auth activate-service-account sa-dev-cloud-storage@edm-saras.iam.gserviceaccount.com --key-file=$DEV_CLOUD_STORAGE_KEY
  script:
    - mkdir temp_config_files
    - gcloud storage cp gs://dev-config-scripts/base-config/* temp_config_files/ --recursive
    - gcloud storage cp gs://dev-client-config/$CLIENT_NAME/* temp_config_files/ --recursive
    - ls -l
    - pwd
    - cd temp_config_files
    - ls -l
    - cd ..
  artifacts:
    paths:
      - temp_config_files/
    expire_in: 1 hour

run_python_script:
  rules:
    - if: $CLIENT_NAME
  stage: Migrate to Client's GitHub
  image: python:3.11.1-slim
  needs:
    - copy_config_files
  dependencies:
    - copy_config_files
  script:
    - ls -l
    - cd temp_config_files
    - pip install pandas openpyxl pyyaml requests
    - python cicd.py
    - ls -l
    - cat git_commands.sh
  artifacts:
    paths:
      - temp_config_files/
      - models/
      - packages.yml
    expire_in: 1 hour

git_push:
  rules:
    - if: $CLIENT_NAME
  stage: Migrate to Client's GitHub
  image: bitnami/git:latest
  needs:
    - run_python_script
  dependencies:
    - run_python_script
  before_script:
    - echo $CI_SERVER_HOST
    - echo $CI_PROJECT_NAMESPACE
    - echo $CI_PROJECT_NAME
    - git config --global user.email "${GIT_USER_EMAIL:-$GITLAB_USER_EMAIL}"
    - git config --global user.name "${GIT_USER_NAME:-$GITLAB_USER_NAME}"
    - apt update -y
    - apt upgrade -y
    - apt install rsync -y
  script:
    - cd temp_config_files
    - ls -l
    - cd ..
    - bash ./temp_config_files/git_commands.sh

bigquery_check:
  only:
    - merge_requests
  stage: Merge Request Check
  image: ubuntu:20.04
  before_script:
    - apt-get upgrade
    - apt-get update -y
    - apt install python3 -y
    - apt-get install python3-pip -y
    - python3 --version # Check python version
    - python3 -m pip install --upgrade dbt-core
    - python3 -m pip install --upgrade dbt-bigquery
    - dbt --version # Check if dbt is intalled properly
    - cat $KEY_FILE_PATH > keyfile.json
    - cat keyfile.json
  script:
    - dbt deps --project-dir . # Install package dependencies
    - "dbt compile --vars '{target_variable: bigquery, snowflake_database_flag: False}' --project-dir . --profiles-dir ./profiles --profile edm_data_transformation --target bigquery --target-path edm_data_transformation"
    - "dbt run --vars '{target_variable: bigquery, snowflake_database_flag: False}' --project-dir . --profiles-dir ./profiles --profile edm_data_transformation --target bigquery --target-path edm_data_transformation"

snowflake_check:
  only:
    - merge_requests
  stage: Merge Request Check
  image: ubuntu:20.04
  before_script:
    - apt-get upgrade
    - apt-get update -y
    - apt install python3 -y
    - apt-get install python3-pip -y
    - python3 --version # Check python version
    - python3 -m pip install --upgrade dbt-core
    - python3 -m pip install --upgrade dbt-snowflake
    - dbt --version # Check if dbt is intalled properly
    - cat $KEY_FILE_PATH > keyfile.json
    - cat keyfile.json
  script:
    - dbt deps --project-dir . # Install package dependencies
    - "dbt compile --vars '{target_variable: snowflake, snowflake_database_flag: True}' --project-dir . --profiles-dir ./profiles --profile edm_data_transformation --target snowflake --target-path edm_data_transformation"
    - "dbt run --vars '{target_variable: snowflake, snowflake_database_flag: True}' --project-dir . --profiles-dir ./profiles --profile edm_data_transformation --target snowflake --target-path edm_data_transformation"
# snowflake_check_test:
#   rules:
#     - if: $CI_PIPELINE_SOURCE == 'push'
#   stage: Merge Request Check
#   image: ubuntu:20.04
#   before_script:
#     - apt-get upgrade
#     - apt-get update -y
#     - apt install python3 -y
#     - apt-get install python3-pip -y
#     - python3 --version # Check python version
#     - python3 -m pip install --upgrade dbt-core
#     - python3 -m pip install --upgrade dbt-snowflake
#     - dbt --version # Check if dbt is intalled properly
#     - cat $KEY_FILE_PATH > keyfile.json
#     - cat keyfile.json
#   script:
#     - dbt deps --project-dir . # Install package dependencies
#     - "dbt compile --vars '{target_variable: snowflake, snowflake_database_flag: True}' --project-dir . --profiles-dir ./profiles --profile edm_data_transformation --target snowflake --target-path edm_data_transformation"
#     - "dbt run --select Staging.AmazonAds --vars '{target_variable: snowflake, snowflake_database_flag: True}' --project-dir . --profiles-dir ./profiles --profile edm_data_transformation --target snowflake --target-path edm_data_transformation"

# bigquery_check_test:
#   rules:
#     - if: $CI_PIPELINE_SOURCE == 'push'
#   stage: Merge Request Check
#   image: ubuntu:20.04
#   before_script:
#     - apt-get upgrade
#     - apt-get update -y
#     - apt install python3 -y
#     - apt-get install python3-pip -y
#     - python3 --version # Check python version
#     - python3 -m pip install --upgrade dbt-core
#     - python3 -m pip install --upgrade dbt-bigquery
#     - dbt --version # Check if dbt is intalled properly
#     - cat $KEY_FILE_PATH > keyfile.json
#     - cat keyfile.json
#   script:
#     - dbt deps --project-dir . # Install package dependencies
#     - "dbt compile --vars '{target_variable: bigquery, snowflake_database_flag: False}' --project-dir . --profiles-dir ./profiles --profile edm_data_transformation --target bigquery --target-path edm_data_transformation"
#     - "dbt run --select Staging.AmazonAds --vars '{target_variable: bigquery, snowflake_database_flag: False}' --project-dir . --profiles-dir ./profiles --profile edm_data_transformation --target bigquery --target-path edm_data_transformation"
